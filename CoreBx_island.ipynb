{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CoreBx_island - Interpolate the North Core Banks DEMs onto rotated 1-m grid and save in a .nc file.\n",
    "\n",
    "May 1, 2022 - Second round of refactoring\n",
    "\n",
    "#### Input:\n",
    "* YAML file with island box params `small_island_box.yml`\n",
    "* DSM tiffs in published format\n",
    "* DSM tiffs that were clipped a second time by Jin-Si to remove sandbars\n",
    "* DSM tiffs from 2019-09 lidar\n",
    "\n",
    "#### Output: in `/crs/proj/2019_DorianOBX/Dorian_paper_analyses/rotated_dems/`:\n",
    "* .nc file with first four published maps as array `[name]_pub.nc`\n",
    "* .nc file with first four re-clipped maps as array `[name]_reclip.nc`\n",
    "* .nc file with two lidar maps (ground and canopy) `[name]_lidar.nc`\n",
    "\n",
    "[name] is provided in the dict loadted from `small_island_box.yml` - Currently `ncorebx_small`\n",
    "\n",
    "TODO: Add better metatdata to the NC files\n",
    "\n",
    "#### Notes:\n",
    " - The reclipped files have funny names because it took several iterations of exporting from GM before their bounds were big enough.  \n",
    " - The lidar data were processed by Andy. `ground` is 50th percentile of points classified ground. `canopy` is 90th percentile of 1st return points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import rioxarray\n",
    "from scipy import interpolate\n",
    "from CoreBx_funcs import *\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on IGSAGIEGLTCHS10\n",
      "drv: C:/\n"
     ]
    }
   ],
   "source": [
    "drv, computername = which_computer()\n",
    "print('Working on',computername)\n",
    "print('drv:',drv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in a dict to define the rotated coordinate system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'ncorebx_small', 'e0': 383520.0, 'n0': 3860830.0, 'xlen': 25000.0, 'ylen': 1200.0, 'dxdy': 1.0, 'theta': 42.0}\n",
      "make_grid: Shape of xrot, yrot:  (1200, 25000) (1200, 25000)\n",
      "corners x, corners y]\n",
      "[[ 383520.03700711 3860830.70613772]\n",
      " [ 402097.91449922 3877558.30216608]\n",
      " [ 401295.62690219 3878449.33281183]\n",
      " [ 382717.74941009 3861721.73678346]\n",
      " [ 383520.03700711 3860830.70613772]]\n",
      "Saving to ncorebx_small.csv\n",
      "Size of grid: 1200 25000\n"
     ]
    }
   ],
   "source": [
    "r = yaml2dict('small_island_box.yml')\n",
    "print(r)\n",
    "\n",
    "# Make a grid \n",
    "xu,yu,xrot,yrot,xcoords,ycoords = make_grid(**r)\n",
    "\n",
    "ny,nx = np.shape(xu)\n",
    "print('Size of grid:',ny,nx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of datasets 4 4\n"
     ]
    }
   ],
   "source": [
    "# Input folders\n",
    "pub_dir = drv+'/crs/proj/2019_DorianOBX/Best_files/dems/'\n",
    "reclip_dir = drv+'/crs/proj/2019_DorianOBX/Best_files/2022-04-22_nosandbars/'\n",
    "lidar_dir = drv+'/crs/proj/2019_DorianOBX/Best_files/lidar/'\n",
    "\n",
    "# output folder for rotated DEMs\n",
    "dem_path =drv+'/crs/proj/2019_DorianOBX/Dorian_paper_analyses/rotated_dems/'\n",
    "\n",
    "# file names for reclipped DSMs (no sandbars)\n",
    "fnames_reclip = (\\\n",
    "           pub_dir+'/20190830_Ocracoke_Inlet_to_Ophelia_Inlet_NAD83_2011_NAVD88_UTM18N_1m_cog.tif',\\\n",
    "           reclip_dir+'/NCB_2019-09-12-13_clipped_cog_r2.tif',\\\n",
    "           reclip_dir+'/NCB_2019-10-11_clipped_cog_reshape.tif',\\\n",
    "           reclip_dir+'/NCB_2019-11-26_clipped_cog_r3.tif')\n",
    "\n",
    "# output file for array of reclipped DSMs\n",
    "reclip_nc = dem_path+r['name']+'_reclip.nc'\n",
    "\n",
    "# file names for published DSMs\n",
    "fnames_pub = (\\\n",
    "           pub_dir+'/20190830_Ocracoke_Inlet_to_Ophelia_Inlet_NAD83_2011_NAVD88_UTM18N_1m_cog.tif',\\\n",
    "           pub_dir+'/20190912-13_Ocracoke_Inlet_to_Ophelia_Inlet_NAD83_2011_NAVD88_UTM18N_1m_cog.tif',\\\n",
    "           pub_dir+'/20191011_Ocracoke_Inlet_to_Cape_Lookout_NAD83_2011_NAVD88_UTM18N_1m_cog.tif',\\\n",
    "           pub_dir+'/20191126_Ocracoke_Inlet_to_Cape_Lookout_NAD83_2011_NAVD88_UTM18N_1m_cog.tif')\n",
    "\n",
    "# output file for array of published DSMs\n",
    "pub_nc = dem_path+r['name']+'_pub.nc'\n",
    "\n",
    "# file names for lidar\n",
    "fnames_lidar = (\\\n",
    "               lidar_dir+'2019_NCMP_PostDorian_CoBa_UTM18_gnd50_UTM18_1m_DSM_cog.tif',\\\n",
    "               lidar_dir+'2019_NCMP_PostDorian_CoBa_UTM18_1st90_UTM18_1m_DSM_cog.tif')\n",
    "\n",
    "# output file for array of lidar DSMs\n",
    "lidar_nc = dem_path+r['name']+'_lidar.nc'\n",
    "\n",
    "titles = ([\\\n",
    "         \"Aug 30 2019 pre-Dorian\",\\\n",
    "         \"Sep 12-13 2019 post-Dorian\",\\\n",
    "         \"Oct 11 2019\",\\\n",
    "         \"Nov 26 2019 post-Nor'easter\"])\n",
    "\n",
    "dates = ([\\\n",
    "         \"2019-08-30\",\\\n",
    "         \"2019-09-12\",\\\n",
    "         \"2019-10-11\",\\\n",
    "         \"2019-11-26\"])\n",
    "\n",
    "nf = len(fnames_reclip)\n",
    "nft = len(titles)\n",
    "print('Length of datasets',nf,nft)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rotate reclipped maps to array, save to .nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 C://crs/proj/2019_DorianOBX/Best_files/dems//20190830_Ocracoke_Inlet_to_Ophelia_Inlet_NAD83_2011_NAVD88_UTM18N_1m_cog.tif\n",
      "(24189,) (27433,) (1, 24189, 27433)\n",
      "(27433,) (24189,) (24189, 27433)\n",
      "1 C://crs/proj/2019_DorianOBX/Best_files/2022-04-22_nosandbars//NCB_2019-09-12-13_clipped_cog_r2.tif\n",
      "(18803,) (21255,) (1, 18803, 21255)\n",
      "(21255,) (18803,) (18803, 21255)\n",
      "2 C://crs/proj/2019_DorianOBX/Best_files/2022-04-22_nosandbars//NCB_2019-10-11_clipped_cog_reshape.tif\n",
      "(19100,) (20940,) (1, 19100, 20940)\n",
      "(20940,) (19100,) (19100, 20940)\n",
      "3 C://crs/proj/2019_DorianOBX/Best_files/2022-04-22_nosandbars//NCB_2019-11-26_clipped_cog_r3.tif\n",
      "(19791,) (22379,) (1, 19791, 22379)\n",
      "(22379,) (19791,) (19791, 22379)\n",
      "CPU times: total: 36.7 s\n",
      "Wall time: 49.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dslist=[]\n",
    "for i, fn in enumerate(fnames_reclip):\n",
    "    iswarned = False\n",
    "    fpath = fn\n",
    "    print(i, fpath)\n",
    "\n",
    "    da = rioxarray.open_rasterio( fpath, masked=True )\n",
    "\n",
    "    print( np.shape(np.flipud(da['y'].values)), np.shape(da['x'].values), np.shape( np.flipud(da.values)) )\n",
    "    x = da['x'].values\n",
    "    y = np.flipud(da['y'].values)\n",
    "\n",
    "    # Not sure how da.values got a singleton dimension, but squeeze gets rid of it.\n",
    "    # However, make sure to squeeze before flipping\n",
    "    z = np.flipud(np.squeeze(da.values))\n",
    "    print(np.shape(x),np.shape(y),np.shape(z))\n",
    "\n",
    "    f = interpolate.RegularGridInterpolator( (y, x), z, method='nearest')   \n",
    "\n",
    "    # Array for interpolated elevations\n",
    "    zi=np.NaN*np.ones((ny,nx))\n",
    "        \n",
    "    # this is the fast iteration, which only works when all of the source points fall inside the target box\n",
    "    try:\n",
    "        zi=f((yu,xu))\n",
    "\n",
    "    # this is a slow iteration through all of the points, but allows us to skip ones that are outside\n",
    "    except:\n",
    "        if(not iswarned):\n",
    "            print(\"Warning: using slow iteration.\")\n",
    "            iswarned = True\n",
    "        for ij in np.ndindex(zi.shape):\n",
    "            try:\n",
    "                zi[ij]=f((yu[ij],xu[ij]))\n",
    "            except:\n",
    "                zi[ij]=np.NaN\n",
    "\n",
    "    #dar = xr.DataArray(zi,dims=['Alongshore','Cross-shore'],coords={'Alongshore': ycoords, 'Cross-shore':xcoords })\n",
    "    dar = xr.DataArray(zi,dims=['Cross-shore','Alongshore'],coords={'Cross-shore': ycoords, 'Alongshore' :xcoords })\n",
    "\n",
    "    dar = dar.chunk()\n",
    "    dslist.append(dar)\n",
    "\n",
    "dsa = xr.concat(dslist, dim='map')\n",
    "\n",
    "# TODO - Add some metadata to this netcdf file. Add time to the maps. Are the dimensions in the right order?\n",
    "\n",
    "dsa.to_netcdf(reclip_nc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rotate published maps to array, save as .nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 C://crs/proj/2019_DorianOBX/Best_files/dems//20190830_Ocracoke_Inlet_to_Ophelia_Inlet_NAD83_2011_NAVD88_UTM18N_1m_cog.tif\n",
      "(24189,) (27433,) (1, 24189, 27433)\n",
      "(27433,) (24189,) (24189, 27433)\n",
      "1 C://crs/proj/2019_DorianOBX/Best_files/dems//20190912-13_Ocracoke_Inlet_to_Ophelia_Inlet_NAD83_2011_NAVD88_UTM18N_1m_cog.tif\n",
      "(23899,) (27276,) (1, 23899, 27276)\n",
      "(27276,) (23899,) (23899, 27276)\n",
      "2 C://crs/proj/2019_DorianOBX/Best_files/dems//20191011_Ocracoke_Inlet_to_Cape_Lookout_NAD83_2011_NAVD88_UTM18N_1m_cog.tif\n",
      "(52966,) (46193,) (1, 52966, 46193)\n",
      "(46193,) (52966,) (52966, 46193)\n",
      "3 C://crs/proj/2019_DorianOBX/Best_files/dems//20191126_Ocracoke_Inlet_to_Cape_Lookout_NAD83_2011_NAVD88_UTM18N_1m_cog.tif\n",
      "(55497,) (47653,) (1, 55497, 47653)\n",
      "(47653,) (55497,) (55497, 47653)\n",
      "CPU times: total: 2min 2s\n",
      "Wall time: 4min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dslist=[]\n",
    "for i, fn in enumerate(fnames_pub):\n",
    "    iswarned = False\n",
    "    fpath = fn\n",
    "    print(i, fpath)\n",
    "\n",
    "    da = rioxarray.open_rasterio( fpath, masked=True )\n",
    "\n",
    "    print( np.shape(np.flipud(da['y'].values)), np.shape(da['x'].values), np.shape( np.flipud(da.values)) )\n",
    "    x = da['x'].values\n",
    "    y = np.flipud(da['y'].values)\n",
    "\n",
    "    # Not sure how da.values got a singleton dimension, but squeeze gets rid of it.\n",
    "    # However, make sure to squeeze before flipping\n",
    "    z = np.flipud(np.squeeze(da.values))\n",
    "    print(np.shape(x),np.shape(y),np.shape(z))\n",
    "\n",
    "    f = interpolate.RegularGridInterpolator( (y, x), z, method='nearest')   \n",
    "\n",
    "    # Array for interpolated elevations\n",
    "    zi=np.NaN*np.ones((ny,nx))\n",
    "        \n",
    "    # this is the fast iteration, which only works when all of the source points fall inside the target box\n",
    "    try:\n",
    "        zi=f((yu,xu))\n",
    "\n",
    "    # this is a slow iteration through all of the points, but allows us to skip ones that are outside\n",
    "    except:\n",
    "        if(not iswarned):\n",
    "            print(\"Warning: using slow iteration.\")\n",
    "            iswarned = True\n",
    "        for ij in np.ndindex(zi.shape):\n",
    "            try:\n",
    "                zi[ij]=f((yu[ij],xu[ij]))\n",
    "            except:\n",
    "                zi[ij]=np.NaN\n",
    "\n",
    "    #dar = xr.DataArray(zi,dims=['Alongshore','Cross-shore'],coords={'Alongshore': ycoords, 'Cross-shore':xcoords })\n",
    "    dar = xr.DataArray(zi,dims=['Cross-shore','Alongshore'],coords={'Cross-shore': ycoords, 'Alongshore' :xcoords })\n",
    "\n",
    "    dar = dar.chunk()\n",
    "    dslist.append(dar)\n",
    "\n",
    "dsa = xr.concat(dslist, dim='map')\n",
    "\n",
    "# TODO - Add some metadata to this netcdf file. Add time to the maps. Are the dimensions in the right order?\n",
    "\n",
    "dsa.to_netcdf(pub_nc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rotate lidar maps to array, save as .nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 C://crs/proj/2019_DorianOBX/Best_files/lidar/2019_NCMP_PostDorian_CoBa_UTM18_gnd50_UTM18_1m_DSM_cog.tif\n",
      "(58539,) (50750,) (1, 58539, 50750)\n",
      "(50750,) (58539,) (58539, 50750)\n",
      "1 C://crs/proj/2019_DorianOBX/Best_files/lidar/2019_NCMP_PostDorian_CoBa_UTM18_1st90_UTM18_1m_DSM_cog.tif\n",
      "(58539,) (50750,) (1, 58539, 50750)\n",
      "(50750,) (58539,) (58539, 50750)\n",
      "CPU times: total: 4min 41s\n",
      "Wall time: 4min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dslist=[]\n",
    "for i, fn in enumerate(fnames_lidar):\n",
    "    iswarned = False\n",
    "    fpath = fn\n",
    "    print(i, fpath)\n",
    "\n",
    "    da = rioxarray.open_rasterio( fpath, masked=True )\n",
    "\n",
    "    print( np.shape(np.flipud(da['y'].values)), np.shape(da['x'].values), np.shape( np.flipud(da.values)) )\n",
    "    x = da['x'].values\n",
    "    y = np.flipud(da['y'].values)\n",
    "\n",
    "    # Not sure how da.values got a singleton dimension, but squeeze gets rid of it.\n",
    "    # However, make sure to squeeze before flipping\n",
    "    z = np.flipud(np.squeeze(da.values))\n",
    "    print(np.shape(x),np.shape(y),np.shape(z))\n",
    "\n",
    "    f = interpolate.RegularGridInterpolator( (y, x), z, method='nearest')   \n",
    "\n",
    "    # Array for interpolated elevations\n",
    "    zi=np.NaN*np.ones((ny,nx))\n",
    "        \n",
    "    # this is the fast iteration, which only works when all of the source points fall inside the target box\n",
    "    try:\n",
    "        zi=f((yu,xu))\n",
    "\n",
    "    # this is a slow iteration through all of the points, but allows us to skip ones that are outside\n",
    "    except:\n",
    "        if(not iswarned):\n",
    "            print(\"Warning: using slow iteration.\")\n",
    "            iswarned = True\n",
    "        for ij in np.ndindex(zi.shape):\n",
    "            try:\n",
    "                zi[ij]=f((yu[ij],xu[ij]))\n",
    "            except:\n",
    "                zi[ij]=np.NaN\n",
    "\n",
    "    #dar = xr.DataArray(zi,dims=['Alongshore','Cross-shore'],coords={'Alongshore': ycoords, 'Cross-shore':xcoords })\n",
    "    dar = xr.DataArray(zi,dims=['Cross-shore','Alongshore'],coords={'Cross-shore': ycoords, 'Alongshore' :xcoords })\n",
    "\n",
    "    dar = dar.chunk()\n",
    "    dslist.append(dar)\n",
    "\n",
    "dsa = xr.concat(dslist, dim='map')\n",
    "\n",
    "# TODO - Add some metadata to this netcdf file. Add time to the maps. Are the dimensions in the right order?\n",
    "\n",
    "dsa.to_netcdf(lidar_nc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
