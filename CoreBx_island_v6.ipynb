{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CoreBx_island_v6 - Try to process entire N. Core Banks\n",
    "\n",
    "Interpolate the North Core Banks DEMs onto rotated 1-m grid and save each as a .nc file.\n",
    "\n",
    "Versioning jumped from v2 to v5, trying to be consistent with versions in processing notebooks.\n",
    "\n",
    "New invV5\n",
    "* Files are switched to the \"merged DEMs\" that Jin-Si made, so the rapid iteration can occur.\n",
    "* Box is re-adjusted to accomodate the whole island. The resulting array is huge, but manageble.\n",
    "\n",
    "New in v2\n",
    "* Now 4D maps, two made made during visit to Santa Cruz and two ftp'd from Andy\n",
    "* Apr. 9 - changed to _v3 for Sep map\n",
    "* Now does the interpolation without the loop\n",
    "* Apr. 21 - moved origin to SE to accomodate curvature in NE end of island. Add 400 m to size of array.\n",
    "* Watch file names, esp. underline (or not) after \"1m_DEM\"\n",
    "\n",
    "New in v6\n",
    "* Added maps through Sep 28 2020\n",
    "\n",
    "TODO: The alongshore/cross-shore names are switched."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "# from dask.distributed import LocalCluster\n",
    "from scipy import interpolate, signal\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define all of the functions by runnng this python file\n",
    "%run -i CoreBx_funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_grid(name=None,e0=None,n0=None,xlen=None,ylen=None,dxdy=None,theta=None):\n",
    "    nx = int((1./dxdy)*xlen)\n",
    "    ny = int((1./dxdy)*ylen)\n",
    "\n",
    "    xcoords = np.linspace(0.5*dxdy,xlen-0.5*dxdy,nx)\n",
    "    ycoords = np.linspace(0.5*dxdy,ylen-0.5*dxdy,ny)\n",
    "\n",
    "    # these will be the coordinates in rotated space\n",
    "    xrot, yrot = np.meshgrid(xcoords, ycoords ,sparse=False, indexing='xy')\n",
    "\n",
    "    print('Shape of xrot, yrot: ',np.shape(xrot),np.shape(yrot))\n",
    "    shp = np.shape(xrot)\n",
    "    xu, yu = box2UTMh(xrot.flatten(), yrot.flatten(), e0, n0, theta)\n",
    "    xu=np.reshape(xu,shp)\n",
    "    yu=np.reshape(yu,shp)\n",
    "    # write the UTM coords of the corners to an ASCII file\n",
    "    corners = np.asarray(  [[xu[0][0],yu[0][0]],\\\n",
    "                           [xu[0][-1],yu[0][-1]],\\\n",
    "                           [xu[-1][-1],yu[-1][-1]],\\\n",
    "                           [xu[-1][0],yu[-1][0]],\\\n",
    "                           [xu[0][0],yu[0][0]]])\n",
    "\n",
    "    print(corners)\n",
    "    fn = name+'.csv'\n",
    "    np.savetxt(fn, corners, delimiter=\",\")\n",
    "    return xu, yu, xrot, yrot, xcoords, ycoords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# April 9, 2020: Replaced   \"2019-09-12-13_1m_DEM_4D_crop.tif\",\\\n",
    "# with _v3 and re-ran on my desktop\n",
    "\n",
    "# May 4 - Changed to use Jin-Si's merged dems\n",
    "\n",
    "fdir = \"C:/crs/proj/2019_DorianOBX/Santa_Cruz_Products/merged_dems/\"\n",
    "#fdir = \"D:/crs/proj/2019_DorianOBX/Santa_Cruz_Products/clipped_dems/\"\n",
    "\n",
    "\n",
    "fnames = (\\\n",
    "          \"C:/crs/proj/2019_DorianOBX/Santa_Cruz_Products/merged_dems/2019-08-30_1m_DEM_4D_crop2_m.tif\",\\\n",
    "          \"C:/crs/proj/2019_DorianOBX/Santa_Cruz_Products/merged_dems/2019-09-12-13_1m_DEM_4D_v3_m.tif\",\\\n",
    "          \"C:/crs/proj/2019_DorianOBX/SfM_OBX_results/dems/NCB_20191011_DEM_1m_lidarMerge_NAD83_2011_UTM18N_NAVD88_cog.tif\",\\\n",
    "          \"C:/crs/proj/2019_DorianOBX/Santa_Cruz_Products/merged_dems/2019-11-26_1m_DEM_4D_crop_m.tif\",\\\n",
    "          \"C:/crs/proj/2019_DorianOBX/SfM_OBX_results/dems/NCB_20200208-09_DEM_1m_4D_NAD83_2011_UTM18N_NAVD88_cog.tif\",\\\n",
    "          \"C:/crs/proj/2019_DorianOBX/SfM_OBX_results/dems/NCB_20200508-09_DEM_1m_4D_NAD83_2011_UTM18N_NAVD88_cog.tif\",\\\n",
    "          \"C:/crs/proj/2019_DorianOBX/SfM_OBX_results/dems/NCB_20200802_DEM_1m_4D_NAD83_2011_UTM18N_NAVD88_cog.tif\",\\\n",
    "          \"C:/crs/proj/2019_DorianOBX/SfM_OBX_results/dems/NCB_20200805-09_DEM_1m_4D_NAD83_2011_UTM18N_NAVD88_cog.tif\",\\\n",
    "          \"C:/crs/proj/2019_DorianOBX/SfM_OBX_results/dems/NCB_20200928_DEM_1m_4D_NAD83_2011_UTM18N_NAVD88_cog.tif\")\n",
    "\n",
    "titles = ([\\\n",
    "         \"Aug 30 2019 pre-Dorian\",\\\n",
    "         \"Sep 12-13 2019 post-Dorian\",\\\n",
    "         \"Oct 11 2019 lidar merge\",\\\n",
    "         \"Nov 26 2019 post-Nor'easter\",\\\n",
    "         \"Feb 8-9 2020\",\\\n",
    "         \"May 8-9 2020\",\\\n",
    "         \"Aug 2 2020 pre-Isaias\",\\\n",
    "         \"Aug 5-9 2020 post-Isaias\",\\\n",
    "         \"Sep 28 2020 post-Teddy\"])\n",
    "nf = len(fnames)\n",
    "\n",
    "fill_fnames = ('EBK_201909_YesLidar_Comb_Extent_m.tif')\n",
    "fill_titles = ('Sep_fill')\n",
    "\n",
    "# optional median-filter smoothing of original maps\n",
    "smooth = False\n",
    "# kernal size...this should be an odd number >= dxy/0.1\n",
    "ksize = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make an array of dicts, where analysis region is defined by:\n",
    "#  name\n",
    "#  e0 - UTM Easting of origin [m]\n",
    "#  n0 - UTM Northing of origin [m]\n",
    "#  xlen - Length of alongshore axis [m]\n",
    "#  ylen - Length of cross-shore axis [m]\n",
    "#  dxdy - grid size (must be isotropic right now) [m]\n",
    "#  theta - rotation CCW from x-axis [deg]\n",
    "\n",
    "r = {'name':\"ncorebx\",\"e0\": 378500.,\"n0\": 3856350.,\"xlen\": 36000.,\"ylen\": 1100.,\"dxdy\": 1.,\"theta\": 42.}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "297.2579301909577 -267.6522425435433\n"
     ]
    }
   ],
   "source": [
    "# move the origin 400 m SE\n",
    "xo,yo = xycoord(400.,42.+90)\n",
    "print(xo,yo)\n",
    "r['e0']=r['e0']+xo\n",
    "r['n0']=r['n0']+yo\n",
    "\n",
    "# add 400 m to ylen\n",
    "r['ylen']=r['ylen']+400.\n",
    "\n",
    "# that was called ncorebx_v4\n",
    "# move that origin 460 m sw\n",
    "xo,yo = xycoord(460., 42.+180.)\n",
    "r['e0']=r['e0']+xo\n",
    "r['n0']=r['n0']+yo\n",
    "# add 650 m to ylen\n",
    "r['xlen']=r['xlen']+650.\n",
    "r['name']='ncorebx_v6'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'ncorebx_v6',\n",
       " 'e0': 378489.45785126585,\n",
       " 'n0': 3855740.5011377367,\n",
       " 'xlen': 36650.0,\n",
       " 'ylen': 1500.0,\n",
       " 'dxdy': 1.0,\n",
       " 'theta': 42.0}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ncorebx_v6\n",
      "Shape of xrot, yrot:  (1500, 36650) (1500, 36650)\n",
      "[[ 378489.49485838 3855741.20727545]\n",
      " [ 405725.0095673  3880264.1748679 ]\n",
      " [ 404721.98278836 3881378.14896129]\n",
      " [ 377486.46807944 3856855.18136884]\n",
      " [ 378489.49485838 3855741.20727545]]\n",
      "1500 36650\n"
     ]
    }
   ],
   "source": [
    "print(r['name'])\n",
    "xu,yu,xrot,yrot,xcoords,ycoords = make_grid(**r)\n",
    "ny,nx = np.shape(xu)\n",
    "print(ny,nx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 C:/crs/proj/2019_DorianOBX/Santa_Cruz_Products/merged_dems/2019-08-30_1m_DEM_4D_crop2_m.tif\n",
      "(26049,) (29111,) (1, 26049, 29111)\n",
      "(29111,) (26049,) (26049, 29111)\n",
      "1 C:/crs/proj/2019_DorianOBX/Santa_Cruz_Products/merged_dems/2019-09-12-13_1m_DEM_4D_v3_m.tif\n",
      "(26049,) (29111,) (1, 26049, 29111)\n",
      "(29111,) (26049,) (26049, 29111)\n",
      "2 C:/crs/proj/2019_DorianOBX/SfM_OBX_results/dems/NCB_20191011_DEM_1m_lidarMerge_NAD83_2011_UTM18N_NAVD88_cog.tif\n",
      "(24700,) (28235,) (1, 24700, 28235)\n",
      "(28235,) (24700,) (24700, 28235)\n",
      "3 C:/crs/proj/2019_DorianOBX/Santa_Cruz_Products/merged_dems/2019-11-26_1m_DEM_4D_crop_m.tif\n",
      "(26049,) (29111,) (1, 26049, 29111)\n",
      "(29111,) (26049,) (26049, 29111)\n",
      "4 C:/crs/proj/2019_DorianOBX/SfM_OBX_results/dems/NCB_20200208-09_DEM_1m_4D_NAD83_2011_UTM18N_NAVD88_cog.tif\n",
      "(33780,) (35875,) (1, 33780, 35875)\n",
      "(35875,) (33780,) (33780, 35875)\n",
      "5 C:/crs/proj/2019_DorianOBX/SfM_OBX_results/dems/NCB_20200508-09_DEM_1m_4D_NAD83_2011_UTM18N_NAVD88_cog.tif\n",
      "(44000,) (51600,) (1, 44000, 51600)\n",
      "(51600,) (44000,) (44000, 51600)\n",
      "6 C:/crs/proj/2019_DorianOBX/SfM_OBX_results/dems/NCB_20200802_DEM_1m_4D_NAD83_2011_UTM18N_NAVD88_cog.tif\n",
      "(33551,) (35731,) (1, 33551, 35731)\n",
      "(35731,) (33551,) (33551, 35731)\n",
      "7 C:/crs/proj/2019_DorianOBX/SfM_OBX_results/dems/NCB_20200805-09_DEM_1m_4D_NAD83_2011_UTM18N_NAVD88_cog.tif\n",
      "(44000,) (51600,) (1, 44000, 51600)\n",
      "(51600,) (44000,) (44000, 51600)\n",
      "8 C:/crs/proj/2019_DorianOBX/SfM_OBX_results/dems/NCB_20200928_DEM_1m_4D_NAD83_2011_UTM18N_NAVD88_cog.tif\n",
      "(66946,) (71294,) (1, 66946, 71294)\n",
      "(71294,) (66946,) (66946, 71294)\n",
      "Wall time: 5h 32min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dslist=[]\n",
    "for i, fn in enumerate(fnames):\n",
    "    print(i, fn)\n",
    "\n",
    "    # open the tif with XArray as a DataArray\n",
    "    da = xr.open_rasterio(fn)\n",
    "\n",
    "    print( np.shape(np.flipud(da['y'].values)), np.shape(da['x'].values), np.shape( np.flipud(da.values)) )\n",
    "    x = da['x'].values\n",
    "    y = np.flipud(da['y'].values)\n",
    "\n",
    "    # Not sure how da.values got a singleton dimension, but squeeze gets rid of it.\n",
    "    # However, make sure to squeeze before flipping\n",
    "    z = np.flipud(np.squeeze(da.values))\n",
    "    print(np.shape(x),np.shape(y),np.shape(z))\n",
    "\n",
    "    if(smooth):\n",
    "        # smooth with 2D running median\n",
    "        zs = signal.medfilt2d(z, kernel_size=ksize)\n",
    "    else:\n",
    "        zs = z\n",
    "\n",
    "    f = interpolate.RegularGridInterpolator( (y, x), zs, method='linear')   \n",
    "\n",
    "    # Array for interpolated elevations\n",
    "    zi=np.NaN*np.ones((ny,nx))\n",
    "        \n",
    "    # this is the fast iteration, which only works when all of the source points fall inside the target box\n",
    "    try:\n",
    "        zi=f((yu,xu))\n",
    "\n",
    "    # this is a slow iteration through all of the points, but allows us to skip ones that are outside\n",
    "    except:\n",
    "        for ij in np.ndindex(zi.shape):\n",
    "            try:\n",
    "                zi[ij]=f((yu[ij],xu[ij]))\n",
    "            except:\n",
    "                zi[ij]=np.NaN\n",
    "\n",
    "    da = xr.DataArray(zi,dims=['Alongshore','Cross-shore'],coords={'Alongshore': ycoords, 'Cross-shore':xcoords })\n",
    "    da = da.chunk()\n",
    "    dslist.append(da)\n",
    "\n",
    "dsa = xr.concat(dslist, dim='map')\n",
    "fn = r['name']+'.nc'\n",
    "dsa.to_netcdf(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/crs/proj/2019_DorianOBX/Santa_Cruz_Products/merged_dems/EBK_201909_YesLidar_Comb_Extent_m.tif\n",
      "(26049,) (29111,) (1, 26049, 29111)\n",
      "(29111,) (26049,) (26049, 29111)\n",
      "Wall time: 46.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Read in the fill map and make netcdf files\n",
    "fn = fdir+fill_fnames\n",
    "print(fn)\n",
    "\n",
    "# open the tif with XArray as a DataArray\n",
    "daf = xr.open_rasterio(fn)\n",
    "\n",
    "print( np.shape(np.flipud(daf['y'].values)), np.shape(daf['x'].values), np.shape( np.flipud(daf.values)) )\n",
    "x = daf['x'].values\n",
    "y = np.flipud(daf['y'].values)\n",
    "\n",
    "# Not sure how da.values got a singleton dimension, but squeeze gets rid of it.\n",
    "# However, make sure to squeeze before flipping\n",
    "z = np.flipud(np.squeeze(daf.values))\n",
    "print(np.shape(x),np.shape(y),np.shape(z))\n",
    "\n",
    "f = interpolate.RegularGridInterpolator( (y, x), z, method='linear')   \n",
    "\n",
    "# Array for interpolated elevations\n",
    "zi=np.NaN*np.ones((ny,nx))\n",
    "\n",
    "# this is a slow iteration through all of the points, but allows us to skip ones that are outside\n",
    "# for ij in np.ndindex(zi.shape):\n",
    "#     try:\n",
    "#         zi[ij]=f((yu[ij],xu[ij]))\n",
    "#     except:\n",
    "#         zi[ij]=np.NaN\n",
    "\n",
    "# this is the fast technique.\n",
    "zi=f((yu,xu))\n",
    "\n",
    "da = xr.DataArray(zi,dims=['Alongshore','Cross-shore'],coords={'Alongshore': ycoords, 'Cross-shore':xcoords })\n",
    "da = da.chunk()\n",
    "\n",
    "fno = r['name']+'_Sep_fill.nc'\n",
    "da.to_netcdf(fno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
